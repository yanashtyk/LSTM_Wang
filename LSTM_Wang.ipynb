{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datafile, flare_label, series_len, start_feature, n_features, mask_value):\n",
    "    df=pd.read_csv(datafile)\n",
    "    df_values=df.values\n",
    "    X=[]\n",
    "    y=[]\n",
    "    tmp=[]\n",
    "    for k in range (start_feature, start_feature+n_features):\n",
    "        tmp.append(mask_value)\n",
    "    for idx in range(0, len(df_values)):\n",
    "        each_series_data=[]\n",
    "        row=df_values[idx]\n",
    "        if flare_label == 'M5' and row[1][0]=='M' and float(row[1][1:]) >=5.0:\n",
    "            label='X'\n",
    "        else:\n",
    "            label=row[1][0]\n",
    "        if flare_label=='M' and label=='X':\n",
    "            label='M'\n",
    "        if flare_label=='C' and (label=='X' or label=='M'):\n",
    "            label='C'\n",
    "        if flare_label=='B' and (label=='X' or label=='M' or label=='C'):\n",
    "            label='B'\n",
    "        if flare_label=='M5' and (label=='M' or label=='C' or label=='B'):\n",
    "            label='N'\n",
    "        if flare_label=='M' and (label=='B' or label=='C'):\n",
    "            label='N'\n",
    "        if flare_label=='C' and label=='B':\n",
    "            label='N'\n",
    "        has_zero_record=False\n",
    "        #if at least one of the 25 physical feature values is missing, then discard it\n",
    "        if flare_label=='C':\n",
    "            if float(row[5])==0.0:\n",
    "                has_zero_record=True\n",
    "            if float(row[7])==0.0:\n",
    "                has_zero_record=True\n",
    "            for k in range(9, 13):\n",
    "                if float(row[k])==0.0:\n",
    "                    has_zero_record=True\n",
    "                    break\n",
    "            for k in range(14, 16):\n",
    "                if float(row[k])==0.0:\n",
    "                    has_zero_record=True\n",
    "                    break\n",
    "            for k in range(18, 21):\n",
    "                if float(row[k])==0.0:\n",
    "                    has_zero_record=True\n",
    "                    break\n",
    "            if float(row[22])==0.0:\n",
    "                has_zero_record=True\n",
    "            for k in range(24, 33):\n",
    "                if float(row[k])==0.0:\n",
    "                    has_zero_record=True\n",
    "                    break\n",
    "            for k in range(38, 42):\n",
    "                if float(row[k])==0.0:\n",
    "                    has_zero_record=True\n",
    "                    break\n",
    "            #check only for C flares prediction\n",
    "            \n",
    "            if has_zero_record is False:\n",
    "                cur_noaa_num=int(row[3])\n",
    "                each_series_data.append(row[start_feature:start_feature+n_features].tolist())\n",
    "                itr_idx=idx-1\n",
    "                while itr_idx>=0 and len(each_series_data)<series_len:\n",
    "                    prev_row=df_values[itr_idx]\n",
    "                    prev_noaa_num=int(prev_row[3])\n",
    "                    if prev_noaa_num!=cur_noaa_num:\n",
    "                        break\n",
    "                    has_zero_record_tmp=False\n",
    "                    if flare_label=='C':\n",
    "                        if float(row[5])==0.0:\n",
    "                            has_zero_record_tmp=True\n",
    "                        if float(row[7])==0.0:\n",
    "                            has_zero_record_tmp=True\n",
    "                        for k in range(9, 13):\n",
    "                            if float(row[k])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                                break\n",
    "                        for k in range(14, 16):\n",
    "                            if float(row[k])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                                break\n",
    "                        for k in range(18, 21):\n",
    "                            if float(row[k])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                                break\n",
    "                        if float(row[22])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                        for k in range(24, 33):\n",
    "                            if float(row[k])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                                break\n",
    "                        for k in range(38, 42):\n",
    "                            if float(row[k])==0.0:\n",
    "                                has_zero_record_tmp=True\n",
    "                                break\n",
    "                                \n",
    "                                #tested only for C flares\n",
    "                    if len(each_series_data)<series_len and has_zero_record_tmp is True:\n",
    "                        each_series_data.insert(0, tmp)\n",
    "                    \n",
    "                    if len(each_series_data)<series_len and has_zero_record_tmp is False:\n",
    "                        each_series_data.insert(0, prev_row[start_feature:start_feature+n_features].tolist())\n",
    "                    itr_idx-=1\n",
    "                while len(each_series_data)>0 and len(each_series_data)<series_len:\n",
    "                    each_series_data.insert(0, tmp)\n",
    "                \n",
    "                if len(each_series_data)>0:\n",
    "                    X.append(np.array(each_series_data).reshape(series_len, n_features).tolist())\n",
    "                    y.append(label)\n",
    "    X_arr=np.array(X)\n",
    "    y_arr=np.array(y)\n",
    "    print(X_arr.shape)\n",
    "    return X_arr, y_arr\n",
    "\n",
    "\n",
    "                        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84577, 10, 14)\n",
      "(26473, 10, 14)\n",
      "(44689, 10, 14)\n"
     ]
    }
   ],
   "source": [
    "flare_label='C'\n",
    "filepath='./'+flare_label+'/'\n",
    "n_features=14\n",
    "num_of_fold=10\n",
    "start_feature=5\n",
    "mask_value=0\n",
    "series_len=10\n",
    "epochs=7\n",
    "batch_size=256\n",
    "nclass=2\n",
    "thlistsize=201\n",
    "thlist=np.linspace(0, 1, thlistsize)\n",
    "\n",
    "X_train_data, y_train_data = load_data(datafile=filepath+'normalized_training.csv', \n",
    "                                       flare_label=flare_label,\n",
    "                                       series_len=series_len,\n",
    "                                       start_feature=start_feature,\n",
    "                                       n_features=n_features,\n",
    "                                       mask_value=mask_value)\n",
    "\n",
    "X_valid_data, y_valid_data=load_data(datafile=filepath+'normalized_validation.csv', \n",
    "                                     flare_label=flare_label,\n",
    "                                     series_len=series_len,\n",
    "                                     start_feature=start_feature,\n",
    "                                     n_features=n_features,\n",
    "                                     mask_value=mask_value)\n",
    "\n",
    "X_test_data, y_test_data=load_data(datafile=filepath+'normalized_testing.csv',\n",
    "                                   flare_label=flare_label,\n",
    "                                   series_len=series_len,\n",
    "                                   start_feature=start_feature,\n",
    "                                   n_features=n_features,\n",
    "                                   mask_value=mask_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(data):\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(data)\n",
    "    encoded_Y=encoder.transform(data)\n",
    "    print(encoded_Y)\n",
    "    converteddata=F.one_hot(torch.Tensor(encoded_Y).long())\n",
    "    return converteddata.float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform_ce(data):\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(data)\n",
    "    encoded_Y=encoder.transform(data)\n",
    "    encoded_Y=np.ones(encoded_Y.shape)-encoded_Y\n",
    "    return encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_layer, vocab_size, **kwards):\n",
    "        super(RNNModel, self).__init__(**kwards)\n",
    "        self.rnn=rnn_layer\n",
    "        self.vocab_size=vocab_size\n",
    "        self.num_hiddens=self.rnn.hidden_size\n",
    "        \n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions=1\n",
    "            self.drop=nn.Dropout(0.5)\n",
    "            self.linear=nn.Linear(self.num_hiddens, 1)\n",
    "            \n",
    "            self.sigm=nn.Sigmoid()\n",
    "        else:\n",
    "            self.num_directions=2\n",
    "            self.linear=nn.Linear(self.num_hiddens*2, self.vocab_size)\n",
    "            \n",
    "    def forward(self, inputs, state):\n",
    "        \n",
    "        inputs=inputs.permute(1, 0, 2)\n",
    "        Y, state=self.rnn(inputs, state)\n",
    "        \n",
    "        h_t=Y[-1, :, :]\n",
    "        \n",
    "        model_output=self.linear(h_t)\n",
    "        return state, model_output\n",
    "    \n",
    "    def begin_state(self, batch_size=1):\n",
    "            #'nn.LSTM takes a tuple of hidden states'\n",
    "            return (torch.zeros((self.num_directions*self.rnn.num_layers, batch_size, self.num_hiddens)), \n",
    "                    torch.zeros((self.num_directions*self.rnn.num_layers, batch_size, self.num_hiddens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch8(model, train_iter, train_exp,  updater,  p,loss,  #@save\n",
    "                    use_random_iter,epoch):\n",
    "    \"\"\"Train a model within one epoch (defined in Chapter 8).\"\"\"\n",
    "    state= None\n",
    "    \n",
    "    count=0\n",
    "    output_all=torch.tensor([])\n",
    "    Y_all=torch.tensor([])\n",
    "    for X, Y in train_iter:\n",
    "        if count!=train_exp:\n",
    "            \n",
    "            if state is None or use_random_iter:\n",
    "                # Initialize `state` when either it is the first iteration or\n",
    "              \n",
    "                state = model.begin_state(batch_size=8457)\n",
    "            else:\n",
    "                if isinstance(model, nn.Module) and not isinstance(state, tuple):\n",
    "                    \n",
    "                    state.detach_()\n",
    "                else:\n",
    "                    # `state` is a tuple of tensors for `nn.LSTM` and\n",
    "                   \n",
    "                    for s in state:\n",
    "                        s.detach_()\n",
    "          \n",
    "            \n",
    "            state, output = model(X, state)\n",
    "            output=torch.squeeze(output)\n",
    "            if epoch==9:\n",
    "                with torch.no_grad():\n",
    "                    output_all=torch.cat((output, output_all), dim=0)\n",
    "                    Y_all=torch.cat((Y, Y_all), dim=0)\n",
    "           \n",
    "            l=loss(output, Y )#+torch.tensor(1.0/8457)*torch.tensor(0.0001)*torch.sum(output**2)\n",
    "           \n",
    "            if isinstance(updater, torch.optim.Optimizer):\n",
    "                updater.zero_grad()\n",
    "                l.backward()\n",
    "                #grad_clipping(model, 1)\n",
    "                updater.step()\n",
    "        count+=1\n",
    "           \n",
    "    if epoch==9:\n",
    "        with torch.no_grad():\n",
    "            cmat=confusion_matrix(Y_all, np.array([output_all[i]>(0.5) for i in range (output_all.shape[0])]))\n",
    "            print(sum(Y_all))\n",
    "            print(Y_all[0:20])\n",
    "            print(output_all[0:20])\n",
    "            print('cmat_train: ')\n",
    "            print(cmat)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(model, train_iter, train_exp, class_weights, lr, num_epochs, \n",
    "              use_random_iter=False):\n",
    "    \"\"\"Train a model (defined in Chapter 8).\"\"\"\n",
    "\n",
    "    loss=nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    # Initialize\n",
    "    optim=torch.optim.Adam(model.parameters(), lr , betas = (0.9, 0.999))\n",
    "    # Train and predict\n",
    "    for epoch in range(num_epochs):\n",
    "        l = train_epoch_ch8(\n",
    "            model, train_iter,train_exp,  optim,class_weights, loss,use_random_iter, epoch)\n",
    "        print(f'loss {l:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "tensor_x = torch.Tensor(X_train_data)\n",
    "tensor_y = torch.Tensor(data_transform_ce(y_train_data))\n",
    "train_dataset=TensorDataset(tensor_x, tensor_y)\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=8457, shuffle=True, drop_last=True)\n",
    "m=16\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all={0:[], 1:[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in train_dataloader:\n",
    "    class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(Y) , y=np.array(Y))\n",
    "    class_weights_all[0].append(class_weights[0])\n",
    "    class_weights_all[1].append(class_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_ts=torch.Tensor(X_test_data)\n",
    "tensor_y_ts=torch.Tensor(data_transform_ce(y_test_data))\n",
    "test_dataset=TensorDataset(tensor_x_ts, tensor_y_ts)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=4468,  shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_recall=0\n",
    "max_precision=0\n",
    "max_acc=0\n",
    "max_tss=0\n",
    "max_far=0\n",
    "max_hss=0\n",
    "recall_list=[]\n",
    "precision_list=[]\n",
    "acc_list=[]\n",
    "hss_list=[]\n",
    "tss_list=[]\n",
    "far_list=[]\n",
    "\n",
    "fraction_of_positives_list=[]\n",
    "mean_predicted_value_list=[]\n",
    "fpr_list=[]\n",
    "tpr_list=[]\n",
    "num_of_folds=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 0 iteration-------------\n",
      "tensor(3.6415)\n",
      "loss 1.0830\n",
      "loss 1.0753\n",
      "loss 1.0487\n",
      "loss 1.0182\n",
      "loss 0.9643\n",
      "loss 0.9400\n",
      "loss 0.9226\n",
      "loss 0.9063\n",
      "loss 0.8766\n",
      "tensor(16418.)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([-0.6732, -0.6259, -0.8795, -0.7864, -0.7312,  1.6167, -0.9842, -0.8629,\n",
      "        -0.6956,  1.3944, -0.9500, -0.7662, -0.5690,  1.6396,  1.1774, -0.4105,\n",
      "        -0.4414, -0.5335,  1.5139, -0.9727])\n",
      "cmat_train: \n",
      "[[51187  8508]\n",
      " [ 6991  9427]]\n",
      "loss 0.8700\n",
      "test loss: tensor(0.7915, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7833.)\n",
      "[[29444  2935]\n",
      " [ 3352  4481]]\n",
      "--------- 1 iteration-------------\n",
      "tensor(3.6189)\n",
      "loss 1.0508\n",
      "loss 1.0187\n",
      "loss 0.9760\n",
      "loss 0.9483\n",
      "loss 0.9392\n",
      "loss 0.9092\n",
      "loss 0.8899\n",
      "loss 0.8876\n",
      "loss 0.8641\n",
      "tensor(16455.)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1.])\n",
      "tensor([-0.6215, -1.2581, -0.9313,  0.7132, -1.0691,  1.0466, -1.2092, -1.0697,\n",
      "        -1.0379,  1.3477, -0.7203, -0.7547,  0.5641, -1.0300, -1.2348, -1.0482,\n",
      "         1.0192, -1.1335, -0.8272,  1.4581])\n",
      "cmat_train: \n",
      "[[50175  9483]\n",
      " [ 6797  9658]]\n",
      "loss 0.8498\n",
      "test loss: tensor(0.7809, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7862.)\n",
      "[[28900  3450]\n",
      " [ 3077  4785]]\n",
      "--------- 2 iteration-------------\n",
      "tensor(3.6343)\n",
      "loss 1.0820\n",
      "loss 1.0403\n",
      "loss 1.0276\n",
      "loss 0.9914\n",
      "loss 0.9479\n",
      "loss 0.9177\n",
      "loss 0.9156\n",
      "loss 0.8883\n",
      "loss 0.8794\n",
      "tensor(16406.)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([-1.0638e+00, -7.5863e-04, -9.2747e-01, -9.9060e-01,  4.6508e-01,\n",
      "         8.5307e-01, -9.5883e-01, -7.8483e-01, -2.3274e-01, -1.0544e+00,\n",
      "        -1.0859e+00,  7.9420e-01,  1.3863e+00, -9.8534e-01, -8.5099e-01,\n",
      "        -1.1425e+00, -6.7107e-01, -1.0633e+00,  1.3973e+00,  7.2869e-01])\n",
      "cmat_train: \n",
      "[[50099  9608]\n",
      " [ 6694  9712]]\n",
      "loss 0.8553\n",
      "test loss: tensor(0.7853, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7850.)\n",
      "[[28759  3603]\n",
      " [ 3091  4759]]\n",
      "--------- 3 iteration-------------\n",
      "tensor(3.6349)\n",
      "loss 1.0694\n",
      "loss 1.0258\n",
      "loss 1.0020\n",
      "loss 0.9581\n",
      "loss 0.9196\n",
      "loss 0.9011\n",
      "loss 0.9080\n",
      "loss 0.8867\n",
      "loss 0.8797\n",
      "tensor(16536.)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0.])\n",
      "tensor([-1.1587,  0.9977, -0.7932,  1.4442, -1.3924,  1.1716,  0.0510,  1.3371,\n",
      "        -1.3056,  0.0847, -0.9004, -0.9579,  0.0498, -0.7198, -1.3599, -0.0824,\n",
      "         1.5485,  1.1855, -0.5332, -1.0027])\n",
      "cmat_train: \n",
      "[[49873  9704]\n",
      " [ 6710  9826]]\n",
      "loss 0.8410\n",
      "test loss: tensor(0.7782, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7839.)\n",
      "[[28702  3671]\n",
      " [ 3074  4765]]\n",
      "--------- 4 iteration-------------\n",
      "tensor(3.6415)\n",
      "loss 1.0842\n",
      "loss 1.0487\n",
      "loss 1.0082\n",
      "loss 0.9610\n",
      "loss 0.9353\n",
      "loss 0.9210\n",
      "loss 0.9068\n",
      "loss 0.8877\n",
      "loss 0.8868\n",
      "tensor(16414.)\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([ 0.0499, -0.8450, -1.0315, -0.7540, -0.8521, -0.9274, -0.4368, -1.0467,\n",
      "        -1.0745, -0.7847, -1.0334,  1.7459,  1.4185,  0.8296,  0.1033,  1.3993,\n",
      "         0.3098, -0.6260, -0.7977, -0.9003])\n",
      "cmat_train: \n",
      "[[51039  8660]\n",
      " [ 7160  9254]]\n",
      "loss 0.8832\n",
      "test loss: tensor(0.7851, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7818.)\n",
      "[[29197  3197]\n",
      " [ 3199  4619]]\n",
      "--------- 5 iteration-------------\n",
      "tensor(3.6423)\n",
      "loss 1.0857\n",
      "loss 1.0433\n",
      "loss 1.0178\n",
      "loss 0.9779\n",
      "loss 0.9471\n",
      "loss 0.9037\n",
      "loss 0.8865\n",
      "loss 0.8862\n",
      "loss 0.8731\n",
      "tensor(16447.)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([-1.0100, -1.0542, -0.9587, -0.9544, -0.5375,  1.1947, -1.0135, -1.1157,\n",
      "        -0.3421, -0.8144,  0.6902,  1.2816, -0.8757,  1.5165, -0.1077,  1.5549,\n",
      "        -0.9178, -1.0974,  0.7098, -0.3915])\n",
      "cmat_train: \n",
      "[[51008  8658]\n",
      " [ 7000  9447]]\n",
      "loss 0.8539\n",
      "test loss: tensor(0.7795, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7857.)\n",
      "[[29153  3202]\n",
      " [ 3147  4710]]\n",
      "--------- 6 iteration-------------\n",
      "tensor(3.6180)\n",
      "loss 1.0692\n",
      "loss 1.0706\n",
      "loss 1.0412\n",
      "loss 0.9923\n",
      "loss 0.9515\n",
      "loss 0.9188\n",
      "loss 0.9247\n",
      "loss 0.9019\n",
      "loss 0.8871\n",
      "tensor(16381.)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([ 1.1175,  1.1655, -0.9399, -1.1276, -0.3097, -1.1571, -0.8124,  1.4315,\n",
      "        -0.5818,  0.4382, -1.1992, -0.6407, -0.2475,  0.4564, -0.5350,  1.3355,\n",
      "        -0.9454, -0.8905, -0.9882, -0.1914])\n",
      "cmat_train: \n",
      "[[50332  9400]\n",
      " [ 6805  9576]]\n",
      "loss 0.8793\n",
      "test loss: tensor(0.7931, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7861.)\n",
      "[[28794  3557]\n",
      " [ 3196  4665]]\n",
      "--------- 7 iteration-------------\n",
      "tensor(3.6201)\n",
      "loss 1.0566\n",
      "loss 1.0441\n",
      "loss 1.0014\n",
      "loss 0.9447\n",
      "loss 0.9531\n",
      "loss 0.9142\n",
      "loss 0.8924\n",
      "loss 0.8781\n",
      "loss 0.8610\n",
      "tensor(16468.)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1.])\n",
      "tensor([-1.1831, -0.4509, -0.9732, -1.0091, -0.9683, -0.9609, -1.2066, -0.9814,\n",
      "         0.9412, -0.9179, -0.7281,  1.2697,  0.1330,  1.1059, -1.0826, -0.2233,\n",
      "         0.9135,  0.7216,  1.4226,  1.6765])\n",
      "cmat_train: \n",
      "[[50999  8646]\n",
      " [ 6996  9472]]\n",
      "loss 0.8579\n",
      "test loss: tensor(0.7750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7868.)\n",
      "[[29265  3079]\n",
      " [ 3166  4702]]\n",
      "--------- 8 iteration-------------\n",
      "tensor(3.6338)\n",
      "loss 1.0803\n",
      "loss 1.0766\n",
      "loss 1.0400\n",
      "loss 1.0369\n",
      "loss 0.9874\n",
      "loss 0.9351\n",
      "loss 0.8966\n",
      "loss 0.8970\n",
      "loss 0.9142\n",
      "tensor(16502.)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1.])\n",
      "tensor([-1.0862, -1.0010, -1.1001,  1.0410, -0.4040,  0.4837, -1.0829, -0.9627,\n",
      "        -0.9795, -0.8904, -0.8847, -1.0540, -1.1261, -1.0615, -0.8226, -0.0839,\n",
      "        -0.9106, -1.0605, -0.9973,  1.5009])\n",
      "cmat_train: \n",
      "[[49859  9752]\n",
      " [ 6638  9864]]\n",
      "loss 0.8704\n",
      "test loss: tensor(0.7914, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7896.)\n",
      "[[28833  3483]\n",
      " [ 3171  4725]]\n",
      "--------- 9 iteration-------------\n",
      "tensor(3.6247)\n",
      "loss 1.0654\n",
      "loss 1.0477\n",
      "loss 0.9905\n",
      "loss 0.9691\n",
      "loss 0.9244\n",
      "loss 0.9065\n",
      "loss 0.8857\n",
      "loss 0.9057\n",
      "loss 0.8880\n",
      "tensor(16499.)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([-0.1665,  1.4438, -1.2645,  1.4635,  1.0936,  1.3006, -1.1692,  1.4931,\n",
      "        -0.5732,  1.5128, -0.9108,  0.8961, -0.9470,  0.8139,  0.4053,  0.2684,\n",
      "        -1.2627, -1.0287, -0.6145, -0.8270])\n",
      "cmat_train: \n",
      "[[50112  9502]\n",
      " [ 6706  9793]]\n",
      "loss 0.8904\n",
      "test loss: tensor(0.7772, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "tensor(7915.)\n",
      "[[28953  3344]\n",
      " [ 3168  4747]]\n"
     ]
    }
   ],
   "source": [
    "for train_itr in range(num_of_folds):\n",
    "        print('--------- '+str(train_itr) + ' iteration-------------')\n",
    "        \n",
    "        test_itr=train_itr\n",
    "        classweights0=(np.sum(class_weights_all[0])-class_weights_all[0][train_itr])/num_of_folds\n",
    "        classweights1=(np.sum(class_weights_all[1])-class_weights_all[1][train_itr])/num_of_folds\n",
    "        classweights=classweights1/ classweights0\n",
    "        classweights=torch.Tensor(np.array(classweights))\n",
    "        print(classweights)\n",
    "        lstm_layer=nn.LSTM(n_features, m,2 )\n",
    "        model=RNNModel(lstm_layer, m)\n",
    "        \n",
    "        train_ch8(model, train_dataloader, train_itr, classweights, lr, num_epochs)\n",
    "        \n",
    "        y_ts_all=torch.tensor([])\n",
    "        output_ts_all=torch.tensor([])\n",
    "        \n",
    "        count=0\n",
    "        for i in test_dataloader:\n",
    "            if count!=test_itr:\n",
    "                x, y=i\n",
    "                output=model(x, model.begin_state(x.shape[0]))\n",
    "                y_ts_all=torch.cat((y, y_ts_all))\n",
    "                output_ts_all=torch.cat((torch.squeeze(output[1]),output_ts_all), dim=0)\n",
    "            count+=1\n",
    "        loss=nn.BCEWithLogitsLoss(pos_weight=classweights)\n",
    "        l=loss(output_ts_all, y_ts_all)\n",
    "        print('test loss: ' + str(l)+ '\\n')\n",
    "        \n",
    "        thresh=0.5\n",
    "        cmat=confusion_matrix(y_ts_all, np.array([output_ts_all[i]>(thresh) for i in range (output_ts_all.shape[0])]))\n",
    "        print(sum(y_ts_all))\n",
    "        print(cmat)\n",
    "        N=np.sum(cmat)\n",
    "            \n",
    "        \n",
    "        tp=cmat[1][1]\n",
    "        fn=cmat[1][0]\n",
    "        fp=cmat[0][1]\n",
    "        tn=cmat[0][0]\n",
    "                \n",
    "        recall=round(float(tp)/float(tp+fn+1e-6), 3)\n",
    "        precision=round(float(tp)/float(tp+fp+1e-6), 3)\n",
    "        accuracy=round(float(tp+tn)/float(N), 3)\n",
    "        far=round(float(fp)/float(fp+tn))\n",
    "        #bacc=round(0.5*(float(tp)/float(tp+fn)+float(tn)/float(tn[p]+fp[p])), 3)\n",
    "        hss=round(2*float(tp*tn-fp*fn)/float((tp+fn)*(fn+tn)+(tp+fp)*(fp+tn)), 3)\n",
    "        tss=round(float(tp)/float(tp+fn+1e-6)-float(fp)/float(fp+tn+1e-6), 3)\n",
    "                \n",
    "        if tss > max_tss:\n",
    "            max_tss=tss\n",
    "            max_far=far\n",
    "            max_hss=hss\n",
    "            max_recall=recall\n",
    "            max_precision=precision\n",
    "            max_acc=accuracy\n",
    "                \n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        acc_list.append(accuracy)\n",
    "        far_list.append(far)\n",
    "        tss_list.append(tss)\n",
    "        hss_list.append(hss)\n",
    "            \n",
    "        \n",
    "                    \n",
    "                    \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_recall=round(np.mean(np.array(recall_list)), 3)\n",
    "std_recall=round(np.std(np.array(recall_list)), 3)\n",
    "    \n",
    "avg_precision=round(np.mean(np.array(precision_list)), 3)\n",
    "std_precision=round(np.std(np.array(precision_list)), 3)\n",
    "    \n",
    "avg_acc=round(np.mean(np.array(acc_list)), 3)\n",
    "std_acc=round(np.std(np.array(acc_list)), 3)\n",
    "    \n",
    "avg_far=round(np.mean(np.array(far_list)), 3)\n",
    "std_far=round(np.std(np.array(far_list)), 3)\n",
    "max_far=round(np.max(np.array(far_list)), 3)\n",
    "min_far=round(np.min(np.array(far_list)), 3)\n",
    "    \n",
    "avg_hss=round(np.mean(np.array(hss_list)), 3)\n",
    "std_hss=round(np.std(np.array(hss_list)), 3)\n",
    "max_hss=round(np.max(np.array(hss_list)), 3)\n",
    "min_hss=round(np.min(np.array(hss_list)), 3)\n",
    "    \n",
    "avg_tss=round(np.mean(np.array(tss_list)), 3)\n",
    "std_tss=round(np.std(np.array(tss_list)), 3)\n",
    "max_tss=round(np.max(np.array(tss_list)), 3)\n",
    "min_tss=round(np.min(np.array(tss_list)), 3)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.5\n",
      "\n",
      "avg recall: 0.597 (0.01)\n",
      "\n",
      "avg precision: 0.584 (0.014)\n",
      "\n",
      "avg acc: 0.838 (0.005)\n",
      "\n",
      "avg hss: 0.489 (0.009)\n",
      "\n",
      "avg tss: 0.494 (0.007)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('threshold: ' +str(0.5)+ '\\n')\n",
    "\n",
    "print('avg recall: '+str(avg_recall) +\n",
    "      ' (' + str(std_recall) + ')\\n')\n",
    "print('avg precision: ' + str(avg_precision)\n",
    "      +' (' + str(std_precision) +')\\n')\n",
    "print('avg acc: ' + str(avg_acc) \n",
    "      + ' (' + str(std_acc) + ')\\n')\n",
    "print('avg hss: ' + str(avg_hss) \n",
    "      + ' (' +str(std_hss) +')\\n')\n",
    "print('avg tss: ' + str(avg_tss)+' ('\n",
    "      +str(std_tss)+ ')\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
